{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "liberal-journalist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>923138734443_VXT_Khwab_IVR_Q_20220822130729.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>923145348816_VXT_Khwab_IVR_Q_20220828143501.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>923154275963_VXT_Mufti_IVR_Q_20221103165253.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>923175135298_VXT_Mufti_IVR_Q_20220418175329.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>923172533943_VXT_Mufti_IVR_Q_20220718195646.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867</th>\n",
       "      <td>923102241416_VXT_Mufti_IVR_Q_20220605100343.wav</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1868</th>\n",
       "      <td>923102191842_VXT_Khwab_IVR_Q_20220913142625.wav</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1869</th>\n",
       "      <td>923087390650_VXT_Mufti_IVR_Q_20220922194920.wav</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1870</th>\n",
       "      <td>923111215175_VXT_Mufti_IVR_Q_20230113220905.wav</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1871</th>\n",
       "      <td>923108192895_VXT_Mufti_IVR_Q_20230111165436.wav</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1872 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 data  label\n",
       "0     923138734443_VXT_Khwab_IVR_Q_20220822130729.wav      0\n",
       "1     923145348816_VXT_Khwab_IVR_Q_20220828143501.wav      0\n",
       "2     923154275963_VXT_Mufti_IVR_Q_20221103165253.wav      0\n",
       "3     923175135298_VXT_Mufti_IVR_Q_20220418175329.wav      0\n",
       "4     923172533943_VXT_Mufti_IVR_Q_20220718195646.wav      0\n",
       "...                                               ...    ...\n",
       "1867  923102241416_VXT_Mufti_IVR_Q_20220605100343.wav      1\n",
       "1868  923102191842_VXT_Khwab_IVR_Q_20220913142625.wav      1\n",
       "1869  923087390650_VXT_Mufti_IVR_Q_20220922194920.wav      1\n",
       "1870  923111215175_VXT_Mufti_IVR_Q_20230113220905.wav      1\n",
       "1871  923108192895_VXT_Mufti_IVR_Q_20230111165436.wav      1\n",
       "\n",
       "[1872 rows x 2 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Extracting MFCC's For every audio file\n",
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "audio_dataset_path='/home/ammar/Desktop/VectraCom/mustanad_jawab/assets/audio_classifier_data_3/audio'\n",
    "metadata=pd.read_csv('/home/ammar/Desktop/VectraCom/mustanad_jawab/assets/audio_classifier_data_3/metadata.csv')\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "chinese-calendar",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_extractor(file_name):\n",
    "    audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "    mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=100)\n",
    "    mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
    "    \n",
    "    return mfccs_scaled_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "nuclear-sponsorship",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "732it [06:42,  1.94it/s]/tmp/ipykernel_34004/107047213.py:2: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast')\n",
      "/home/ammar/anaconda3/envs/m_jawab/lib/python3.9/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "982it [08:50,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1003it [08:57,  4.15it/s]/home/ammar/anaconda3/envs/m_jawab/lib/python3.9/site-packages/librosa/core/spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=882\n",
      "  warnings.warn(\n",
      "1008it [08:58,  4.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1012it [09:00,  2.81it/s]/home/ammar/anaconda3/envs/m_jawab/lib/python3.9/site-packages/librosa/core/spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=882\n",
      "  warnings.warn(\n",
      "1019it [09:02,  2.52it/s]/tmp/ipykernel_34004/107047213.py:2: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast')\n",
      "/home/ammar/anaconda3/envs/m_jawab/lib/python3.9/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
      "1021it [09:03,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1027it [09:04,  4.72it/s]/home/ammar/anaconda3/envs/m_jawab/lib/python3.9/site-packages/librosa/core/spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=1323\n",
      "  warnings.warn(\n",
      "1038it [09:07,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1046it [09:10,  2.78it/s]/home/ammar/anaconda3/envs/m_jawab/lib/python3.9/site-packages/librosa/core/spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=1764\n",
      "  warnings.warn(\n",
      "1055it [09:12,  4.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1069it [09:15,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1104it [09:24,  5.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1122it [09:28,  5.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1127it [09:29,  4.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1182it [09:45,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1195it [09:49,  2.33it/s]/home/ammar/anaconda3/envs/m_jawab/lib/python3.9/site-packages/librosa/core/spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=441\n",
      "  warnings.warn(\n",
      "1210it [09:54,  3.04it/s]/home/ammar/anaconda3/envs/m_jawab/lib/python3.9/site-packages/librosa/core/spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=882\n",
      "  warnings.warn(\n",
      "1220it [09:55,  7.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1295it [10:17,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1307it [10:21,  4.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1318it [10:23,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1323it [10:24,  5.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1340it [10:29,  4.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1352it [10:32,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1366it [10:37,  4.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1373it [10:38,  6.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1387it [10:43,  2.51it/s]/tmp/ipykernel_34004/107047213.py:2: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast')\n",
      "/home/ammar/anaconda3/envs/m_jawab/lib/python3.9/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
      "1388it [10:43,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1391it [10:44,  3.86it/s]/tmp/ipykernel_34004/107047213.py:2: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast')\n",
      "/home/ammar/anaconda3/envs/m_jawab/lib/python3.9/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
      "1392it [10:44,  4.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1397it [10:45,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1409it [10:49,  3.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1424it [10:54,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1450it [11:01,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1455it [11:02,  4.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1462it [11:04,  2.96it/s]/home/ammar/anaconda3/envs/m_jawab/lib/python3.9/site-packages/librosa/core/spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=1764\n",
      "  warnings.warn(\n",
      "1483it [11:11,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1488it [11:12,  4.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1490it [11:12,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1505it [11:18,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1512it [11:22,  2.05it/s]/tmp/ipykernel_34004/107047213.py:2: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast')\n",
      "/home/ammar/anaconda3/envs/m_jawab/lib/python3.9/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
      "1513it [11:22,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1525it [11:27,  3.28it/s]/home/ammar/anaconda3/envs/m_jawab/lib/python3.9/site-packages/librosa/core/spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=882\n",
      "  warnings.warn(\n",
      "1527it [11:27,  4.55it/s]/tmp/ipykernel_34004/107047213.py:2: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast')\n",
      "/home/ammar/anaconda3/envs/m_jawab/lib/python3.9/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
      "1530it [11:27,  5.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1538it [11:30,  3.95it/s]/home/ammar/anaconda3/envs/m_jawab/lib/python3.9/site-packages/librosa/core/spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=1323\n",
      "  warnings.warn(\n",
      "1545it [11:32,  3.41it/s]/tmp/ipykernel_34004/107047213.py:2: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast')\n",
      "/home/ammar/anaconda3/envs/m_jawab/lib/python3.9/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
      "1546it [11:32,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1548it [11:33,  2.61it/s]/tmp/ipykernel_34004/107047213.py:2: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast')\n",
      "/home/ammar/anaconda3/envs/m_jawab/lib/python3.9/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
      "1549it [11:33,  2.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1571it [11:41,  3.60it/s]/home/ammar/anaconda3/envs/m_jawab/lib/python3.9/site-packages/librosa/core/spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=1764\n",
      "  warnings.warn(\n",
      "1585it [11:45,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1590it [11:47,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1627it [11:59,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1632it [12:01,  2.40it/s]/tmp/ipykernel_34004/107047213.py:2: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast')\n",
      "/home/ammar/anaconda3/envs/m_jawab/lib/python3.9/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
      "1635it [12:02,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1648it [12:05,  6.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1654it [12:06,  5.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1665it [12:08,  6.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1676it [12:11,  4.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1681it [12:13,  3.08it/s]/tmp/ipykernel_34004/107047213.py:2: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast')\n",
      "/home/ammar/anaconda3/envs/m_jawab/lib/python3.9/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
      "1682it [12:13,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1686it [12:14,  4.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1697it [12:18,  2.70it/s]/home/ammar/anaconda3/envs/m_jawab/lib/python3.9/site-packages/librosa/core/spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=1323\n",
      "  warnings.warn(\n",
      "1699it [12:18,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1703it [12:19,  3.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1712it [12:22,  3.61it/s]/home/ammar/anaconda3/envs/m_jawab/lib/python3.9/site-packages/librosa/core/spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=441\n",
      "  warnings.warn(\n",
      "/home/ammar/anaconda3/envs/m_jawab/lib/python3.9/site-packages/librosa/core/spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=882\n",
      "  warnings.warn(\n",
      "1736it [12:29,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1760it [12:36,  3.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1762it [12:36,  3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1807it [12:48,  4.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1813it [12:50,  3.02it/s]/home/ammar/anaconda3/envs/m_jawab/lib/python3.9/site-packages/librosa/core/spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=1764\n",
      "  warnings.warn(\n",
      "1834it [12:55,  5.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1841it [12:56,  7.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1872it [13:05,  2.38it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "### Now we iterate through every audio file and extract features \n",
    "### using Mel-Frequency Cepstral Coefficients\n",
    "extracted_features=[]\n",
    "for index_num,row in tqdm(metadata.iterrows()):\n",
    "    file_name = os.path.join(os.path.abspath(audio_dataset_path), row['data'])\n",
    "    final_class_labels=row[\"label\"]\n",
    "    try:\n",
    "        data=features_extractor(file_name)\n",
    "        extracted_features.append([data,final_class_labels])\n",
    "    except:\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acoustic-wagner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-450.9607, 96.12279, 3.1271524, -4.126467, 10...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-276.5172, 160.59642, -23.35358, 2.7810037, 2...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-359.56778, 137.5303, -8.403525, 0.32247916, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-363.8008, 125.774765, 8.171007, -6.7005568, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-335.10977, 166.44395, -19.066479, 2.4823332,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1813</th>\n",
       "      <td>[-482.88425, 112.45296, -22.121681, 3.061062, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1814</th>\n",
       "      <td>[-522.8835, 81.40097, -9.058278, -15.703022, -...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1815</th>\n",
       "      <td>[-590.49774, 122.81329, -12.286636, -4.2238126...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1816</th>\n",
       "      <td>[-1120.5901, 10.758279, 6.4419518, 8.032725, 8...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1817</th>\n",
       "      <td>[-441.1377, 180.42589, -59.077766, 2.648793, 2...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1818 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                feature  class\n",
       "0     [-450.9607, 96.12279, 3.1271524, -4.126467, 10...      0\n",
       "1     [-276.5172, 160.59642, -23.35358, 2.7810037, 2...      0\n",
       "2     [-359.56778, 137.5303, -8.403525, 0.32247916, ...      0\n",
       "3     [-363.8008, 125.774765, 8.171007, -6.7005568, ...      0\n",
       "4     [-335.10977, 166.44395, -19.066479, 2.4823332,...      0\n",
       "...                                                 ...    ...\n",
       "1813  [-482.88425, 112.45296, -22.121681, 3.061062, ...      1\n",
       "1814  [-522.8835, 81.40097, -9.058278, -15.703022, -...      1\n",
       "1815  [-590.49774, 122.81329, -12.286636, -4.2238126...      1\n",
       "1816  [-1120.5901, 10.758279, 6.4419518, 8.032725, 8...      1\n",
       "1817  [-441.1377, 180.42589, -59.077766, 2.648793, 2...      1\n",
       "\n",
       "[1818 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### converting extracted_features to Pandas dataframe\n",
    "extracted_features_df=pd.DataFrame(extracted_features,columns=['feature','class'])\n",
    "extracted_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "962e5bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                feature  class\n",
      "0     [-450.9607, 96.12279, 3.1271524, -4.126467, 10...      0\n",
      "1     [-276.5172, 160.59642, -23.35358, 2.7810037, 2...      0\n",
      "2     [-359.56778, 137.5303, -8.403525, 0.32247916, ...      0\n",
      "3     [-363.8008, 125.774765, 8.171007, -6.7005568, ...      0\n",
      "4     [-335.10977, 166.44395, -19.066479, 2.4823332,...      0\n",
      "...                                                 ...    ...\n",
      "1813  [-482.88425, 112.45296, -22.121681, 3.061062, ...      1\n",
      "1814  [-522.8835, 81.40097, -9.058278, -15.703022, -...      1\n",
      "1815  [-590.49774, 122.81329, -12.286636, -4.2238126...      1\n",
      "1816  [-1120.5901, 10.758279, 6.4419518, 8.032725, 8...      1\n",
      "1817  [-441.1377, 180.42589, -59.077766, 2.648793, 2...      1\n",
      "\n",
      "[1818 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(extracted_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "characteristic-sudan",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Split the dataset into independent and dependent dataset\n",
    "X=np.array(extracted_features_df['feature'].tolist())\n",
    "y=np.array(extracted_features_df['class'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "friendly-placement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1818, 100)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "wired-church",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Label Encoding\n",
    "y=np.array(pd.get_dummies(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sitting-anniversary",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "documentary-priority",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyzed-payday",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "female-study",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flexible-lithuania",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instrumental-equity",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chemical-vermont",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governing-natural",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "express-vessel",
   "metadata": {},
   "source": [
    "### Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "loose-portugal",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-17 14:20:49.731188: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-04-17 14:20:49.731232: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-04-17 14:20:51.144833: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-04-17 14:20:51.145110: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-04-17 14:20:51.145138: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "indonesian-accessory",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Activation,Flatten\n",
    "from keras.optimizers import Adam\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "valuable-substitute",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### No of classes\n",
    "num_labels=y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1eee7558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "found-outside",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-17 14:21:00.103203: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-04-17 14:21:00.103292: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-04-17 14:21:00.103347: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ammar-ubuntu): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "###first layer\n",
    "model.add(Dense(150,input_shape=(100,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "###second layer\n",
    "model.add(Dense(200))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "###third layer\n",
    "model.add(Dense(250))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.4))\n",
    "###fourth layer\n",
    "model.add(Dense(200))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "###fifth layer\n",
    "model.add(Dense(150))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "###final layer\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "described-anaheim",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 150)               15150     \n",
      "                                                                 \n",
      " activation (Activation)     (None, 150)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 150)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 200)               30200     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 200)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 200)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 250)               50250     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 250)               0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 250)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 200)               50200     \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 200)               0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 200)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 150)               30150     \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 150)               0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 150)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 2)                 302       \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 176,252\n",
      "Trainable params: 176,252\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "radical-finding",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.001)\n",
    "model.compile(loss='binary_crossentropy',metrics=['accuracy'],optimizer=optimizer)\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "alpha-adapter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.5058 - accuracy: 0.8260\n",
      "Epoch 1: val_loss improved from inf to 0.22386, saving model to saved_models/model_(3).hdf5\n",
      "23/23 [==============================] - 3s 46ms/step - loss: 0.5058 - accuracy: 0.8260 - val_loss: 0.2239 - val_accuracy: 0.9176\n",
      "Epoch 2/200\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.4690 - accuracy: 0.8425\n",
      "Epoch 2: val_loss improved from 0.22386 to 0.21901, saving model to saved_models/model_(3).hdf5\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 0.4690 - accuracy: 0.8425 - val_loss: 0.2190 - val_accuracy: 0.9203\n",
      "Epoch 3/200\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.4827 - accuracy: 0.8177\n",
      "Epoch 3: val_loss did not improve from 0.21901\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.4770 - accuracy: 0.8212 - val_loss: 0.2217 - val_accuracy: 0.9176\n",
      "Epoch 4/200\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 0.4482 - accuracy: 0.8469\n",
      "Epoch 4: val_loss improved from 0.21901 to 0.21759, saving model to saved_models/model_(3).hdf5\n",
      "23/23 [==============================] - 1s 26ms/step - loss: 0.4396 - accuracy: 0.8480 - val_loss: 0.2176 - val_accuracy: 0.9121\n",
      "Epoch 5/200\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.4467 - accuracy: 0.8295\n",
      "Epoch 5: val_loss improved from 0.21759 to 0.20667, saving model to saved_models/model_(3).hdf5\n",
      "23/23 [==============================] - 1s 22ms/step - loss: 0.4413 - accuracy: 0.8322 - val_loss: 0.2067 - val_accuracy: 0.9258\n",
      "Epoch 6/200\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 0.4228 - accuracy: 0.8492\n",
      "Epoch 6: val_loss improved from 0.20667 to 0.20250, saving model to saved_models/model_(3).hdf5\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 0.4141 - accuracy: 0.8535 - val_loss: 0.2025 - val_accuracy: 0.9203\n",
      "Epoch 7/200\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.3976 - accuracy: 0.8631\n",
      "Epoch 7: val_loss improved from 0.20250 to 0.19416, saving model to saved_models/model_(3).hdf5\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.3905 - accuracy: 0.8666 - val_loss: 0.1942 - val_accuracy: 0.9231\n",
      "Epoch 8/200\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 0.3782 - accuracy: 0.8695\n",
      "Epoch 8: val_loss improved from 0.19416 to 0.19207, saving model to saved_models/model_(3).hdf5\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.3784 - accuracy: 0.8714 - val_loss: 0.1921 - val_accuracy: 0.9286\n",
      "Epoch 9/200\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.3605 - accuracy: 0.8787\n",
      "Epoch 9: val_loss improved from 0.19207 to 0.19078, saving model to saved_models/model_(3).hdf5\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 0.3622 - accuracy: 0.8790 - val_loss: 0.1908 - val_accuracy: 0.9313\n",
      "Epoch 10/200\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.3811 - accuracy: 0.8786\n",
      "Epoch 10: val_loss improved from 0.19078 to 0.19070, saving model to saved_models/model_(3).hdf5\n",
      "23/23 [==============================] - 1s 28ms/step - loss: 0.3831 - accuracy: 0.8769 - val_loss: 0.1907 - val_accuracy: 0.9313\n",
      "Epoch 11/200\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.3767 - accuracy: 0.8643\n",
      "Epoch 11: val_loss improved from 0.19070 to 0.18961, saving model to saved_models/model_(3).hdf5\n",
      "23/23 [==============================] - 0s 22ms/step - loss: 0.3742 - accuracy: 0.8666 - val_loss: 0.1896 - val_accuracy: 0.9286\n",
      "Epoch 12/200\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.3662 - accuracy: 0.8720\n",
      "Epoch 12: val_loss improved from 0.18961 to 0.18910, saving model to saved_models/model_(3).hdf5\n",
      "23/23 [==============================] - 0s 22ms/step - loss: 0.3702 - accuracy: 0.8700 - val_loss: 0.1891 - val_accuracy: 0.9313\n",
      "Epoch 13/200\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.3490 - accuracy: 0.8832\n",
      "Epoch 13: val_loss did not improve from 0.18910\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.3509 - accuracy: 0.8831 - val_loss: 0.1907 - val_accuracy: 0.9258\n",
      "Epoch 14/200\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.3494 - accuracy: 0.8828\n",
      "Epoch 14: val_loss improved from 0.18910 to 0.18337, saving model to saved_models/model_(3).hdf5\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.3501 - accuracy: 0.8810 - val_loss: 0.1834 - val_accuracy: 0.9286\n",
      "Epoch 15/200\n",
      "19/23 [=======================>......] - ETA: 0s - loss: 0.3269 - accuracy: 0.8906\n",
      "Epoch 15: val_loss improved from 0.18337 to 0.18080, saving model to saved_models/model_(3).hdf5\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.3162 - accuracy: 0.8955 - val_loss: 0.1808 - val_accuracy: 0.9341\n",
      "Epoch 16/200\n",
      "19/23 [=======================>......] - ETA: 0s - loss: 0.3519 - accuracy: 0.8873\n",
      "Epoch 16: val_loss did not improve from 0.18080\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.3326 - accuracy: 0.8948 - val_loss: 0.1848 - val_accuracy: 0.9341\n",
      "Epoch 17/200\n",
      "18/23 [======================>.......] - ETA: 0s - loss: 0.3330 - accuracy: 0.8845\n",
      "Epoch 17: val_loss did not improve from 0.18080\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.3322 - accuracy: 0.8858 - val_loss: 0.1821 - val_accuracy: 0.9341\n",
      "Epoch 18/200\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.3216 - accuracy: 0.8949\n",
      "Epoch 18: val_loss did not improve from 0.18080\n",
      "23/23 [==============================] - 1s 37ms/step - loss: 0.3293 - accuracy: 0.8913 - val_loss: 0.1850 - val_accuracy: 0.9313\n",
      "Epoch 19/200\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.3238 - accuracy: 0.8854\n",
      "Epoch 19: val_loss improved from 0.18080 to 0.17801, saving model to saved_models/model_(3).hdf5\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.3237 - accuracy: 0.8865 - val_loss: 0.1780 - val_accuracy: 0.9341\n",
      "Epoch 20/200\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.3181 - accuracy: 0.9027\n",
      "Epoch 20: val_loss improved from 0.17801 to 0.17620, saving model to saved_models/model_(3).hdf5\n",
      "23/23 [==============================] - 1s 21ms/step - loss: 0.3177 - accuracy: 0.9030 - val_loss: 0.1762 - val_accuracy: 0.9341\n",
      "Epoch 21/200\n",
      "18/23 [======================>.......] - ETA: 0s - loss: 0.2987 - accuracy: 0.9054\n",
      "Epoch 21: val_loss did not improve from 0.17620\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.3121 - accuracy: 0.9030 - val_loss: 0.1815 - val_accuracy: 0.9286\n",
      "Epoch 22/200\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 0.3086 - accuracy: 0.8914\n",
      "Epoch 22: val_loss did not improve from 0.17620\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 0.3116 - accuracy: 0.8906 - val_loss: 0.1768 - val_accuracy: 0.9341\n",
      "Epoch 23/200\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.3034 - accuracy: 0.9092\n",
      "Epoch 23: val_loss improved from 0.17620 to 0.17584, saving model to saved_models/model_(3).hdf5\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.3034 - accuracy: 0.9092 - val_loss: 0.1758 - val_accuracy: 0.9341\n",
      "Epoch 24/200\n",
      "19/23 [=======================>......] - ETA: 0s - loss: 0.3046 - accuracy: 0.9046\n",
      "Epoch 24: val_loss did not improve from 0.17584\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 0.3010 - accuracy: 0.9051 - val_loss: 0.1793 - val_accuracy: 0.9341\n",
      "Epoch 25/200\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.3141 - accuracy: 0.8999\n",
      "Epoch 25: val_loss improved from 0.17584 to 0.17494, saving model to saved_models/model_(3).hdf5\n",
      "23/23 [==============================] - 1s 42ms/step - loss: 0.3166 - accuracy: 0.8989 - val_loss: 0.1749 - val_accuracy: 0.9341\n",
      "Epoch 26/200\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.2952 - accuracy: 0.9072\n",
      "Epoch 26: val_loss improved from 0.17494 to 0.17321, saving model to saved_models/model_(3).hdf5\n",
      "23/23 [==============================] - 1s 32ms/step - loss: 0.2952 - accuracy: 0.9072 - val_loss: 0.1732 - val_accuracy: 0.9341\n",
      "Epoch 27/200\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.3150 - accuracy: 0.9027\n",
      "Epoch 27: val_loss did not improve from 0.17321\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.3122 - accuracy: 0.9030 - val_loss: 0.1733 - val_accuracy: 0.9368\n",
      "Epoch 28/200\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.2990 - accuracy: 0.9010\n",
      "Epoch 28: val_loss improved from 0.17321 to 0.17255, saving model to saved_models/model_(3).hdf5\n",
      "23/23 [==============================] - 1s 34ms/step - loss: 0.2991 - accuracy: 0.9023 - val_loss: 0.1725 - val_accuracy: 0.9341\n",
      "Epoch 29/200\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.3034 - accuracy: 0.9129\n",
      "Epoch 29: val_loss improved from 0.17255 to 0.17056, saving model to saved_models/model_(3).hdf5\n",
      "23/23 [==============================] - 1s 26ms/step - loss: 0.2982 - accuracy: 0.9154 - val_loss: 0.1706 - val_accuracy: 0.9341\n",
      "Epoch 30/200\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.2940 - accuracy: 0.9055\n",
      "Epoch 30: val_loss improved from 0.17056 to 0.17035, saving model to saved_models/model_(3).hdf5\n",
      "23/23 [==============================] - 1s 22ms/step - loss: 0.2913 - accuracy: 0.9051 - val_loss: 0.1704 - val_accuracy: 0.9313\n",
      "Epoch 31/200\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.2831 - accuracy: 0.9058\n",
      "Epoch 31: val_loss improved from 0.17035 to 0.16855, saving model to saved_models/model_(3).hdf5\n",
      "23/23 [==============================] - 1s 22ms/step - loss: 0.2831 - accuracy: 0.9058 - val_loss: 0.1685 - val_accuracy: 0.9368\n",
      "Epoch 32/200\n",
      "19/23 [=======================>......] - ETA: 0s - loss: 0.2925 - accuracy: 0.9202\n",
      "Epoch 32: val_loss improved from 0.16855 to 0.16763, saving model to saved_models/model_(3).hdf5\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.2868 - accuracy: 0.9188 - val_loss: 0.1676 - val_accuracy: 0.9396\n",
      "Epoch 33/200\n",
      "19/23 [=======================>......] - ETA: 0s - loss: 0.3169 - accuracy: 0.8980\n",
      "Epoch 33: val_loss improved from 0.16763 to 0.16642, saving model to saved_models/model_(3).hdf5\n",
      "23/23 [==============================] - 0s 22ms/step - loss: 0.3092 - accuracy: 0.8982 - val_loss: 0.1664 - val_accuracy: 0.9368\n",
      "Epoch 34/200\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.2706 - accuracy: 0.9161\n",
      "Epoch 34: val_loss did not improve from 0.16642\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.2706 - accuracy: 0.9161 - val_loss: 0.1690 - val_accuracy: 0.9341\n",
      "Epoch 35/200\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.2938 - accuracy: 0.9048\n",
      "Epoch 35: val_loss did not improve from 0.16642\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.2890 - accuracy: 0.9065 - val_loss: 0.1678 - val_accuracy: 0.9368\n",
      "Epoch 36/200\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.2731 - accuracy: 0.9106\n",
      "Epoch 36: val_loss did not improve from 0.16642\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.2731 - accuracy: 0.9106 - val_loss: 0.1675 - val_accuracy: 0.9341\n",
      "Epoch 37/200\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.2896 - accuracy: 0.9077\n",
      "Epoch 37: val_loss did not improve from 0.16642\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.2905 - accuracy: 0.9072 - val_loss: 0.1726 - val_accuracy: 0.9423\n",
      "Epoch 38/200\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.2762 - accuracy: 0.9077\n",
      "Epoch 38: val_loss did not improve from 0.16642\n",
      "23/23 [==============================] - 1s 28ms/step - loss: 0.2817 - accuracy: 0.9065 - val_loss: 0.1719 - val_accuracy: 0.9423\n",
      "Epoch 39/200\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.2709 - accuracy: 0.9167\n",
      "Epoch 39: val_loss did not improve from 0.16642\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.2701 - accuracy: 0.9154 - val_loss: 0.1704 - val_accuracy: 0.9396\n",
      "Epoch 40/200\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.2645 - accuracy: 0.9134\n",
      "Epoch 40: val_loss did not improve from 0.16642\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.2642 - accuracy: 0.9140 - val_loss: 0.1692 - val_accuracy: 0.9313\n",
      "Epoch 41/200\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.2801 - accuracy: 0.9113\n",
      "Epoch 41: val_loss did not improve from 0.16642\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.2801 - accuracy: 0.9113 - val_loss: 0.1706 - val_accuracy: 0.9313\n",
      "Epoch 42/200\n",
      "19/23 [=======================>......] - ETA: 0s - loss: 0.2662 - accuracy: 0.9194\n",
      "Epoch 42: val_loss did not improve from 0.16642\n",
      "23/23 [==============================] - 1s 38ms/step - loss: 0.2749 - accuracy: 0.9168 - val_loss: 0.1674 - val_accuracy: 0.9396\n",
      "Epoch 43/200\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.2799 - accuracy: 0.9127\n",
      "Epoch 43: val_loss did not improve from 0.16642\n",
      "23/23 [==============================] - 1s 26ms/step - loss: 0.2799 - accuracy: 0.9127 - val_loss: 0.1680 - val_accuracy: 0.9396\n",
      "Epoch 44/200\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.2747 - accuracy: 0.9098\n",
      "Epoch 44: val_loss did not improve from 0.16642\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.2714 - accuracy: 0.9113 - val_loss: 0.1683 - val_accuracy: 0.9341\n",
      "Epoch 45/200\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.2633 - accuracy: 0.9107\n",
      "Epoch 45: val_loss improved from 0.16642 to 0.16581, saving model to saved_models/model_(3).hdf5\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 0.2680 - accuracy: 0.9078 - val_loss: 0.1658 - val_accuracy: 0.9368\n",
      "Epoch 46/200\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.2674 - accuracy: 0.9196\n",
      "Epoch 46: val_loss improved from 0.16581 to 0.16358, saving model to saved_models/model_(3).hdf5\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.2662 - accuracy: 0.9202 - val_loss: 0.1636 - val_accuracy: 0.9368\n",
      "Epoch 47/200\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.2794 - accuracy: 0.9169\n",
      "Epoch 47: val_loss did not improve from 0.16358\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.2748 - accuracy: 0.9188 - val_loss: 0.1649 - val_accuracy: 0.9423\n",
      "Epoch 48/200\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 0.2511 - accuracy: 0.9195\n",
      "Epoch 48: val_loss improved from 0.16358 to 0.16215, saving model to saved_models/model_(3).hdf5\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.2635 - accuracy: 0.9175 - val_loss: 0.1622 - val_accuracy: 0.9396\n",
      "Epoch 49/200\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.2734 - accuracy: 0.9129\n",
      "Epoch 49: val_loss improved from 0.16215 to 0.16156, saving model to saved_models/model_(3).hdf5\n",
      "23/23 [==============================] - 1s 26ms/step - loss: 0.2675 - accuracy: 0.9168 - val_loss: 0.1616 - val_accuracy: 0.9368\n",
      "Epoch 50/200\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.2495 - accuracy: 0.9263\n",
      "Epoch 50: val_loss did not improve from 0.16156\n",
      "23/23 [==============================] - 1s 26ms/step - loss: 0.2512 - accuracy: 0.9271 - val_loss: 0.1616 - val_accuracy: 0.9368\n",
      "Epoch 51/200\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.2847 - accuracy: 0.9216\n",
      "Epoch 51: val_loss improved from 0.16156 to 0.15969, saving model to saved_models/model_(3).hdf5\n",
      "23/23 [==============================] - 1s 22ms/step - loss: 0.2847 - accuracy: 0.9216 - val_loss: 0.1597 - val_accuracy: 0.9368\n",
      "Epoch 52/200\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.2668 - accuracy: 0.9219\n",
      "Epoch 52: val_loss did not improve from 0.15969\n",
      "23/23 [==============================] - 1s 26ms/step - loss: 0.2646 - accuracy: 0.9216 - val_loss: 0.1632 - val_accuracy: 0.9478\n",
      "Epoch 53/200\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.2524 - accuracy: 0.9155\n",
      "Epoch 53: val_loss did not improve from 0.15969\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.2574 - accuracy: 0.9154 - val_loss: 0.1616 - val_accuracy: 0.9423\n",
      "Epoch 54/200\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.2520 - accuracy: 0.9174\n",
      "Epoch 54: val_loss did not improve from 0.15969\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.2539 - accuracy: 0.9154 - val_loss: 0.1646 - val_accuracy: 0.9368\n",
      "Epoch 55/200\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.2561 - accuracy: 0.9211\n",
      "Epoch 55: val_loss did not improve from 0.15969\n",
      "23/23 [==============================] - 1s 34ms/step - loss: 0.2544 - accuracy: 0.9230 - val_loss: 0.1608 - val_accuracy: 0.9368\n",
      "Epoch 56/200\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.2650 - accuracy: 0.9152\n",
      "Epoch 56: val_loss improved from 0.15969 to 0.15571, saving model to saved_models/model_(3).hdf5\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.2635 - accuracy: 0.9154 - val_loss: 0.1557 - val_accuracy: 0.9368\n",
      "Epoch 57/200\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.2466 - accuracy: 0.9271\n",
      "Epoch 57: val_loss improved from 0.15571 to 0.15501, saving model to saved_models/model_(3).hdf5\n",
      "23/23 [==============================] - 1s 28ms/step - loss: 0.2492 - accuracy: 0.9257 - val_loss: 0.1550 - val_accuracy: 0.9396\n",
      "Epoch 58/200\n",
      "19/23 [=======================>......] - ETA: 0s - loss: 0.2296 - accuracy: 0.9334\n",
      "Epoch 58: val_loss did not improve from 0.15501\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.2538 - accuracy: 0.9257 - val_loss: 0.1568 - val_accuracy: 0.9368\n",
      "Epoch 59/200\n",
      "19/23 [=======================>......] - ETA: 0s - loss: 0.2359 - accuracy: 0.9227\n",
      "Epoch 59: val_loss did not improve from 0.15501\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 0.2360 - accuracy: 0.9257 - val_loss: 0.1578 - val_accuracy: 0.9368\n",
      "Epoch 60/200\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.2631 - accuracy: 0.9216\n",
      "Epoch 60: val_loss did not improve from 0.15501\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.2631 - accuracy: 0.9216 - val_loss: 0.1591 - val_accuracy: 0.9451\n",
      "Epoch 61/200\n",
      "18/23 [======================>.......] - ETA: 0s - loss: 0.2601 - accuracy: 0.9262\n",
      "Epoch 61: val_loss did not improve from 0.15501\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.2467 - accuracy: 0.9264 - val_loss: 0.1567 - val_accuracy: 0.9368\n",
      "Epoch 62/200\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.2511 - accuracy: 0.9268\n",
      "Epoch 62: val_loss did not improve from 0.15501\n",
      "23/23 [==============================] - 1s 45ms/step - loss: 0.2522 - accuracy: 0.9264 - val_loss: 0.1621 - val_accuracy: 0.9505\n",
      "Epoch 63/200\n",
      "18/23 [======================>.......] - ETA: 0s - loss: 0.2579 - accuracy: 0.9184\n",
      "Epoch 63: val_loss did not improve from 0.15501\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.2622 - accuracy: 0.9161 - val_loss: 0.1571 - val_accuracy: 0.9396\n",
      "Epoch 64/200\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.2344 - accuracy: 0.9285\n",
      "Epoch 64: val_loss did not improve from 0.15501\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.2344 - accuracy: 0.9285 - val_loss: 0.1555 - val_accuracy: 0.9396\n",
      "Epoch 65/200\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.2520 - accuracy: 0.9276\n",
      "Epoch 65: val_loss improved from 0.15501 to 0.15456, saving model to saved_models/model_(3).hdf5\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.2500 - accuracy: 0.9285 - val_loss: 0.1546 - val_accuracy: 0.9396\n",
      "Epoch 66/200\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.2666 - accuracy: 0.9226\n",
      "Epoch 66: val_loss improved from 0.15456 to 0.15434, saving model to saved_models/model_(3).hdf5\n",
      "23/23 [==============================] - 1s 34ms/step - loss: 0.2617 - accuracy: 0.9230 - val_loss: 0.1543 - val_accuracy: 0.9368\n",
      "Epoch 67/200\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.2408 - accuracy: 0.9256\n",
      "Epoch 67: val_loss did not improve from 0.15434\n",
      "23/23 [==============================] - 0s 22ms/step - loss: 0.2343 - accuracy: 0.9278 - val_loss: 0.1547 - val_accuracy: 0.9451\n",
      "Epoch 68/200\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.2566 - accuracy: 0.9257\n",
      "Epoch 68: val_loss did not improve from 0.15434\n",
      "23/23 [==============================] - 1s 33ms/step - loss: 0.2566 - accuracy: 0.9257 - val_loss: 0.1549 - val_accuracy: 0.9396\n",
      "Epoch 69/200\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.2435 - accuracy: 0.9209\n",
      "Epoch 69: val_loss improved from 0.15434 to 0.15186, saving model to saved_models/model_(3).hdf5\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.2435 - accuracy: 0.9209 - val_loss: 0.1519 - val_accuracy: 0.9396\n",
      "Epoch 70/200\n",
      "19/23 [=======================>......] - ETA: 0s - loss: 0.2472 - accuracy: 0.9252\n",
      "Epoch 70: val_loss did not improve from 0.15186\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.2543 - accuracy: 0.9202 - val_loss: 0.1528 - val_accuracy: 0.9505\n",
      "Epoch 71/200\n",
      "19/23 [=======================>......] - ETA: 0s - loss: 0.2511 - accuracy: 0.9235\n",
      "Epoch 71: val_loss improved from 0.15186 to 0.15174, saving model to saved_models/model_(3).hdf5\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.2483 - accuracy: 0.9195 - val_loss: 0.1517 - val_accuracy: 0.9396\n",
      "Epoch 72/200\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.2523 - accuracy: 0.9219\n",
      "Epoch 72: val_loss did not improve from 0.15174\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.2490 - accuracy: 0.9237 - val_loss: 0.1518 - val_accuracy: 0.9423\n",
      "Epoch 73/200\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.2411 - accuracy: 0.9162\n",
      "Epoch 73: val_loss did not improve from 0.15174\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.2403 - accuracy: 0.9175 - val_loss: 0.1525 - val_accuracy: 0.9505\n",
      "Epoch 74/200\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.2383 - accuracy: 0.9271\n",
      "Epoch 74: val_loss did not improve from 0.15174\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 0.2383 - accuracy: 0.9271 - val_loss: 0.1535 - val_accuracy: 0.9478\n",
      "Epoch 75/200\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.2426 - accuracy: 0.9278\n",
      "Epoch 75: val_loss did not improve from 0.15174\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.2400 - accuracy: 0.9257 - val_loss: 0.1549 - val_accuracy: 0.9423\n",
      "Epoch 76/200\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.2496 - accuracy: 0.9196\n",
      "Epoch 76: val_loss did not improve from 0.15174\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.2430 - accuracy: 0.9216 - val_loss: 0.1535 - val_accuracy: 0.9396\n",
      "Epoch 77/200\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.2375 - accuracy: 0.9305\n",
      "Epoch 77: val_loss did not improve from 0.15174\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.2375 - accuracy: 0.9305 - val_loss: 0.1532 - val_accuracy: 0.9396\n",
      "Epoch 78/200\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.2351 - accuracy: 0.9247\n",
      "Epoch 78: val_loss improved from 0.15174 to 0.15051, saving model to saved_models/model_(3).hdf5\n",
      "23/23 [==============================] - 1s 35ms/step - loss: 0.2326 - accuracy: 0.9264 - val_loss: 0.1505 - val_accuracy: 0.9396\n",
      "Epoch 79/200\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.2445 - accuracy: 0.9256\n",
      "Epoch 79: val_loss did not improve from 0.15051\n",
      "23/23 [==============================] - 1s 34ms/step - loss: 0.2444 - accuracy: 0.9271 - val_loss: 0.1556 - val_accuracy: 0.9423\n",
      "Epoch 80/200\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 0.2218 - accuracy: 0.9383\n",
      "Epoch 80: val_loss did not improve from 0.15051\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 0.2405 - accuracy: 0.9319 - val_loss: 0.1750 - val_accuracy: 0.9341\n",
      "Epoch 81/200\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.2506 - accuracy: 0.9202\n",
      "Epoch 81: val_loss did not improve from 0.15051\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 0.2506 - accuracy: 0.9202 - val_loss: 0.1541 - val_accuracy: 0.9396\n",
      "Epoch 82/200\n",
      "19/23 [=======================>......] - ETA: 0s - loss: 0.2421 - accuracy: 0.9243\n",
      "Epoch 82: val_loss did not improve from 0.15051\n",
      "23/23 [==============================] - 1s 33ms/step - loss: 0.2365 - accuracy: 0.9257 - val_loss: 0.1514 - val_accuracy: 0.9478\n",
      "Epoch 83/200\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.2401 - accuracy: 0.9257\n",
      "Epoch 83: val_loss improved from 0.15051 to 0.14882, saving model to saved_models/model_(3).hdf5\n",
      "23/23 [==============================] - 0s 22ms/step - loss: 0.2401 - accuracy: 0.9257 - val_loss: 0.1488 - val_accuracy: 0.9368\n",
      "Epoch 84/200\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.2380 - accuracy: 0.9241\n",
      "Epoch 84: val_loss did not improve from 0.14882\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.2433 - accuracy: 0.9223 - val_loss: 0.1489 - val_accuracy: 0.9396\n",
      "Epoch 85/200\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.2362 - accuracy: 0.9278\n",
      "Epoch 85: val_loss improved from 0.14882 to 0.14783, saving model to saved_models/model_(3).hdf5\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 0.2342 - accuracy: 0.9285 - val_loss: 0.1478 - val_accuracy: 0.9423\n",
      "Epoch 86/200\n",
      "19/23 [=======================>......] - ETA: 0s - loss: 0.2463 - accuracy: 0.9202\n",
      "Epoch 86: val_loss did not improve from 0.14783\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.2362 - accuracy: 0.9237 - val_loss: 0.1486 - val_accuracy: 0.9396\n",
      "Epoch 87/200\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 0.2270 - accuracy: 0.9289\n",
      "Epoch 87: val_loss improved from 0.14783 to 0.14768, saving model to saved_models/model_(3).hdf5\n",
      "23/23 [==============================] - 1s 40ms/step - loss: 0.2391 - accuracy: 0.9292 - val_loss: 0.1477 - val_accuracy: 0.9423\n",
      "Epoch 88/200\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.2369 - accuracy: 0.9292\n",
      "Epoch 88: val_loss did not improve from 0.14768\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 0.2369 - accuracy: 0.9292 - val_loss: 0.1485 - val_accuracy: 0.9451\n",
      "Epoch 89/200\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.2230 - accuracy: 0.9297\n",
      "Epoch 89: val_loss did not improve from 0.14768\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 0.2280 - accuracy: 0.9298 - val_loss: 0.1517 - val_accuracy: 0.9533\n",
      "Epoch 90/200\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.2399 - accuracy: 0.9216\n",
      "Epoch 90: val_loss did not improve from 0.14768\n",
      "23/23 [==============================] - 1s 35ms/step - loss: 0.2399 - accuracy: 0.9216 - val_loss: 0.1494 - val_accuracy: 0.9396\n",
      "Epoch 91/200\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.2460 - accuracy: 0.9257\n",
      "Epoch 91: val_loss did not improve from 0.14768\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 0.2460 - accuracy: 0.9257 - val_loss: 0.1500 - val_accuracy: 0.9423\n",
      "Epoch 92/200\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.2323 - accuracy: 0.9292\n",
      "Epoch 92: val_loss did not improve from 0.14768\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.2323 - accuracy: 0.9292 - val_loss: 0.1499 - val_accuracy: 0.9396\n",
      "Epoch 93/200\n",
      "19/23 [=======================>......] - ETA: 0s - loss: 0.2368 - accuracy: 0.9260\n",
      "Epoch 93: val_loss did not improve from 0.14768\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.2360 - accuracy: 0.9278 - val_loss: 0.1484 - val_accuracy: 0.9423\n",
      "Epoch 94/200\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.2475 - accuracy: 0.9240\n",
      "Epoch 94: val_loss did not improve from 0.14768\n",
      "23/23 [==============================] - 1s 33ms/step - loss: 0.2433 - accuracy: 0.9264 - val_loss: 0.1520 - val_accuracy: 0.9396\n",
      "Epoch 95/200\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.2263 - accuracy: 0.9249\n",
      "Epoch 95: val_loss did not improve from 0.14768\n",
      "23/23 [==============================] - 1s 39ms/step - loss: 0.2259 - accuracy: 0.9237 - val_loss: 0.1512 - val_accuracy: 0.9396\n",
      "Epoch 96/200\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.2193 - accuracy: 0.9292\n",
      "Epoch 96: val_loss did not improve from 0.14768\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.2193 - accuracy: 0.9292 - val_loss: 0.1499 - val_accuracy: 0.9505\n",
      "Epoch 97/200\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.2390 - accuracy: 0.9249\n",
      "Epoch 97: val_loss improved from 0.14768 to 0.14733, saving model to saved_models/model_(3).hdf5\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.2449 - accuracy: 0.9257 - val_loss: 0.1473 - val_accuracy: 0.9396\n",
      "Epoch 98/200\n",
      "19/23 [=======================>......] - ETA: 0s - loss: 0.2339 - accuracy: 0.9252\n",
      "Epoch 98: val_loss improved from 0.14733 to 0.14641, saving model to saved_models/model_(3).hdf5\n",
      "23/23 [==============================] - 1s 28ms/step - loss: 0.2317 - accuracy: 0.9257 - val_loss: 0.1464 - val_accuracy: 0.9451\n",
      "Epoch 99/200\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.2443 - accuracy: 0.9211\n",
      "Epoch 99: val_loss did not improve from 0.14641\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 0.2393 - accuracy: 0.9243 - val_loss: 0.1526 - val_accuracy: 0.9533\n",
      "Epoch 100/200\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.2360 - accuracy: 0.9268\n",
      "Epoch 100: val_loss improved from 0.14641 to 0.14601, saving model to saved_models/model_(3).hdf5\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 0.2322 - accuracy: 0.9285 - val_loss: 0.1460 - val_accuracy: 0.9505\n",
      "Epoch 101/200\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.2006 - accuracy: 0.9298\n",
      "Epoch 101: val_loss did not improve from 0.14601\n",
      "23/23 [==============================] - 1s 33ms/step - loss: 0.2006 - accuracy: 0.9298 - val_loss: 0.1514 - val_accuracy: 0.9396\n",
      "Epoch 102/200\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.2368 - accuracy: 0.9283\n",
      "Epoch 102: val_loss improved from 0.14601 to 0.14302, saving model to saved_models/model_(3).hdf5\n",
      "23/23 [==============================] - 1s 34ms/step - loss: 0.2336 - accuracy: 0.9285 - val_loss: 0.1430 - val_accuracy: 0.9396\n",
      "Epoch 103/200\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.2279 - accuracy: 0.9196\n",
      "Epoch 103: val_loss improved from 0.14302 to 0.14280, saving model to saved_models/model_(3).hdf5\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.2248 - accuracy: 0.9230 - val_loss: 0.1428 - val_accuracy: 0.9423\n",
      "Epoch 104/200\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.2160 - accuracy: 0.9340\n",
      "Epoch 104: val_loss did not improve from 0.14280\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.2160 - accuracy: 0.9340 - val_loss: 0.1444 - val_accuracy: 0.9423\n",
      "Epoch 105/200\n",
      "19/23 [=======================>......] - ETA: 0s - loss: 0.2302 - accuracy: 0.9309\n",
      "Epoch 105: val_loss did not improve from 0.14280\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 0.2357 - accuracy: 0.9285 - val_loss: 0.1451 - val_accuracy: 0.9451\n",
      "Epoch 106/200\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.2302 - accuracy: 0.9311\n",
      "Epoch 106: val_loss did not improve from 0.14280\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 0.2281 - accuracy: 0.9319 - val_loss: 0.1436 - val_accuracy: 0.9396\n",
      "Epoch 107/200\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 0.2225 - accuracy: 0.9336\n",
      "Epoch 107: val_loss did not improve from 0.14280\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 0.2190 - accuracy: 0.9326 - val_loss: 0.1484 - val_accuracy: 0.9423\n",
      "Epoch 108/200\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.2411 - accuracy: 0.9256\n",
      "Epoch 108: val_loss did not improve from 0.14280\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.2395 - accuracy: 0.9264 - val_loss: 0.1438 - val_accuracy: 0.9478\n",
      "Epoch 109/200\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.2255 - accuracy: 0.9276\n",
      "Epoch 109: val_loss did not improve from 0.14280\n",
      "23/23 [==============================] - 1s 35ms/step - loss: 0.2230 - accuracy: 0.9285 - val_loss: 0.1437 - val_accuracy: 0.9396\n",
      "Epoch 110/200\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.2191 - accuracy: 0.9325\n",
      "Epoch 110: val_loss improved from 0.14280 to 0.14120, saving model to saved_models/model_(3).hdf5\n",
      "23/23 [==============================] - 1s 35ms/step - loss: 0.2236 - accuracy: 0.9305 - val_loss: 0.1412 - val_accuracy: 0.9478\n",
      "Epoch 111/200\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.2328 - accuracy: 0.9325\n",
      "Epoch 111: val_loss did not improve from 0.14120\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.2295 - accuracy: 0.9333 - val_loss: 0.1420 - val_accuracy: 0.9478\n",
      "Epoch 112/200\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.2141 - accuracy: 0.9323\n",
      "Epoch 112: val_loss did not improve from 0.14120\n",
      "23/23 [==============================] - 1s 35ms/step - loss: 0.2168 - accuracy: 0.9319 - val_loss: 0.1428 - val_accuracy: 0.9451\n",
      "Epoch 113/200\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.2229 - accuracy: 0.9290\n",
      "Epoch 113: val_loss did not improve from 0.14120\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.2229 - accuracy: 0.9285 - val_loss: 0.1453 - val_accuracy: 0.9451\n",
      "Epoch 114/200\n",
      "19/23 [=======================>......] - ETA: 0s - loss: 0.2201 - accuracy: 0.9342\n",
      "Epoch 114: val_loss did not improve from 0.14120\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.2290 - accuracy: 0.9292 - val_loss: 0.1475 - val_accuracy: 0.9396\n",
      "Epoch 115/200\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.2042 - accuracy: 0.9338\n",
      "Epoch 115: val_loss did not improve from 0.14120\n",
      "23/23 [==============================] - 1s 28ms/step - loss: 0.2076 - accuracy: 0.9340 - val_loss: 0.1432 - val_accuracy: 0.9423\n",
      "Epoch 116/200\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.2213 - accuracy: 0.9390\n",
      "Epoch 116: val_loss did not improve from 0.14120\n",
      "23/23 [==============================] - 1s 33ms/step - loss: 0.2289 - accuracy: 0.9374 - val_loss: 0.1448 - val_accuracy: 0.9451\n",
      "Epoch 117/200\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.2230 - accuracy: 0.9285\n",
      "Epoch 117: val_loss did not improve from 0.14120\n",
      "23/23 [==============================] - 1s 41ms/step - loss: 0.2230 - accuracy: 0.9285 - val_loss: 0.1415 - val_accuracy: 0.9423\n",
      "Epoch 118/200\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 0.2140 - accuracy: 0.9328\n",
      "Epoch 118: val_loss did not improve from 0.14120\n",
      "23/23 [==============================] - 1s 28ms/step - loss: 0.2169 - accuracy: 0.9319 - val_loss: 0.1481 - val_accuracy: 0.9396\n",
      "Epoch 119/200\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.2159 - accuracy: 0.9318\n",
      "Epoch 119: val_loss did not improve from 0.14120\n",
      "23/23 [==============================] - 0s 22ms/step - loss: 0.2208 - accuracy: 0.9298 - val_loss: 0.1449 - val_accuracy: 0.9423\n",
      "Epoch 120/200\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.2298 - accuracy: 0.9330\n",
      "Epoch 120: val_loss did not improve from 0.14120\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.2292 - accuracy: 0.9326 - val_loss: 0.1457 - val_accuracy: 0.9396\n",
      "Epoch 121/200\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.2278 - accuracy: 0.9263\n",
      "Epoch 121: val_loss did not improve from 0.14120\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.2249 - accuracy: 0.9271 - val_loss: 0.1439 - val_accuracy: 0.9451\n",
      "Epoch 122/200\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.2058 - accuracy: 0.9325\n",
      "Epoch 122: val_loss did not improve from 0.14120\n",
      "23/23 [==============================] - 1s 26ms/step - loss: 0.2049 - accuracy: 0.9340 - val_loss: 0.1439 - val_accuracy: 0.9478\n",
      "Epoch 123/200\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.2302 - accuracy: 0.9256\n",
      "Epoch 123: val_loss did not improve from 0.14120\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.2262 - accuracy: 0.9271 - val_loss: 0.1419 - val_accuracy: 0.9423\n",
      "Epoch 124/200\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.2180 - accuracy: 0.9308\n",
      "Epoch 124: val_loss did not improve from 0.14120\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 0.2203 - accuracy: 0.9326 - val_loss: 0.1455 - val_accuracy: 0.9560\n",
      "Epoch 125/200\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.2210 - accuracy: 0.9360\n",
      "Epoch 125: val_loss did not improve from 0.14120\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 0.2182 - accuracy: 0.9360 - val_loss: 0.1417 - val_accuracy: 0.9478\n",
      "Epoch 126/200\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.2071 - accuracy: 0.9330\n",
      "Epoch 126: val_loss did not improve from 0.14120\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.2073 - accuracy: 0.9333 - val_loss: 0.1432 - val_accuracy: 0.9423\n",
      "Epoch 127/200\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 0.2292 - accuracy: 0.9359\n",
      "Epoch 127: val_loss did not improve from 0.14120\n",
      "23/23 [==============================] - 0s 22ms/step - loss: 0.2289 - accuracy: 0.9360 - val_loss: 0.1435 - val_accuracy: 0.9588\n",
      "Epoch 128/200\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 0.1981 - accuracy: 0.9391\n",
      "Epoch 128: val_loss did not improve from 0.14120\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.2105 - accuracy: 0.9340 - val_loss: 0.1419 - val_accuracy: 0.9478\n",
      "Epoch 129/200\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.2119 - accuracy: 0.9340\n",
      "Epoch 129: val_loss improved from 0.14120 to 0.13980, saving model to saved_models/model_(3).hdf5\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.2119 - accuracy: 0.9340 - val_loss: 0.1398 - val_accuracy: 0.9588\n",
      "Epoch 130/200\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 0.2227 - accuracy: 0.9312\n",
      "Epoch 130: val_loss improved from 0.13980 to 0.13939, saving model to saved_models/model_(3).hdf5\n",
      "23/23 [==============================] - 1s 22ms/step - loss: 0.2249 - accuracy: 0.9305 - val_loss: 0.1394 - val_accuracy: 0.9478\n",
      "Epoch 131/200\n",
      "19/23 [=======================>......] - ETA: 0s - loss: 0.2169 - accuracy: 0.9326\n",
      "Epoch 131: val_loss did not improve from 0.13939\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.2274 - accuracy: 0.9292 - val_loss: 0.1402 - val_accuracy: 0.9478\n",
      "Epoch 132/200\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.2044 - accuracy: 0.9347\n",
      "Epoch 132: val_loss improved from 0.13939 to 0.13933, saving model to saved_models/model_(3).hdf5\n",
      "23/23 [==============================] - 1s 26ms/step - loss: 0.2044 - accuracy: 0.9347 - val_loss: 0.1393 - val_accuracy: 0.9478\n",
      "Epoch 133/200\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 0.2110 - accuracy: 0.9328\n",
      "Epoch 133: val_loss did not improve from 0.13933\n",
      "23/23 [==============================] - 1s 46ms/step - loss: 0.2193 - accuracy: 0.9285 - val_loss: 0.1400 - val_accuracy: 0.9396\n",
      "Epoch 134/200\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.2227 - accuracy: 0.9323\n",
      "Epoch 134: val_loss improved from 0.13933 to 0.13873, saving model to saved_models/model_(3).hdf5\n",
      "23/23 [==============================] - 1s 26ms/step - loss: 0.2209 - accuracy: 0.9340 - val_loss: 0.1387 - val_accuracy: 0.9423\n",
      "Epoch 135/200\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.1988 - accuracy: 0.9390\n",
      "Epoch 135: val_loss did not improve from 0.13873\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.2138 - accuracy: 0.9333 - val_loss: 0.1451 - val_accuracy: 0.9560\n",
      "Epoch 136/200\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.2155 - accuracy: 0.9339\n",
      "Epoch 136: val_loss did not improve from 0.13873\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.2142 - accuracy: 0.9333 - val_loss: 0.1394 - val_accuracy: 0.9478\n",
      "Epoch 137/200\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.2185 - accuracy: 0.9308\n",
      "Epoch 137: val_loss improved from 0.13873 to 0.13785, saving model to saved_models/model_(3).hdf5\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.2220 - accuracy: 0.9305 - val_loss: 0.1379 - val_accuracy: 0.9451\n",
      "Epoch 138/200\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.2155 - accuracy: 0.9297\n",
      "Epoch 138: val_loss did not improve from 0.13785\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.2147 - accuracy: 0.9285 - val_loss: 0.1397 - val_accuracy: 0.9560\n",
      "Epoch 139/200\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.2338 - accuracy: 0.9304\n",
      "Epoch 139: val_loss did not improve from 0.13785\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.2297 - accuracy: 0.9326 - val_loss: 0.1381 - val_accuracy: 0.9478\n",
      "Epoch 140/200\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.2141 - accuracy: 0.9354\n",
      "Epoch 140: val_loss did not improve from 0.13785\n",
      "23/23 [==============================] - 1s 26ms/step - loss: 0.2110 - accuracy: 0.9367 - val_loss: 0.1428 - val_accuracy: 0.9560\n",
      "Epoch 141/200\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.2191 - accuracy: 0.9338\n",
      "Epoch 141: val_loss did not improve from 0.13785\n",
      "23/23 [==============================] - 1s 36ms/step - loss: 0.2163 - accuracy: 0.9340 - val_loss: 0.1420 - val_accuracy: 0.9588\n",
      "Epoch 142/200\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.2092 - accuracy: 0.9318\n",
      "Epoch 142: val_loss did not improve from 0.13785\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.2106 - accuracy: 0.9312 - val_loss: 0.1384 - val_accuracy: 0.9423\n",
      "Epoch 143/200\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.2102 - accuracy: 0.9286\n",
      "Epoch 143: val_loss did not improve from 0.13785\n",
      "23/23 [==============================] - 1s 35ms/step - loss: 0.2098 - accuracy: 0.9305 - val_loss: 0.1399 - val_accuracy: 0.9560\n",
      "Epoch 144/200\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.2071 - accuracy: 0.9374\n",
      "Epoch 144: val_loss did not improve from 0.13785\n",
      "23/23 [==============================] - 1s 44ms/step - loss: 0.2071 - accuracy: 0.9374 - val_loss: 0.1422 - val_accuracy: 0.9560\n",
      "Epoch 145/200\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.2048 - accuracy: 0.9339\n",
      "Epoch 145: val_loss improved from 0.13785 to 0.13608, saving model to saved_models/model_(3).hdf5\n",
      "23/23 [==============================] - 1s 36ms/step - loss: 0.2063 - accuracy: 0.9326 - val_loss: 0.1361 - val_accuracy: 0.9478\n",
      "Epoch 146/200\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.1984 - accuracy: 0.9382\n",
      "Epoch 146: val_loss improved from 0.13608 to 0.13567, saving model to saved_models/model_(3).hdf5\n",
      "23/23 [==============================] - 1s 36ms/step - loss: 0.2029 - accuracy: 0.9367 - val_loss: 0.1357 - val_accuracy: 0.9505\n",
      "Epoch 147/200\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.2120 - accuracy: 0.9333\n",
      "Epoch 147: val_loss did not improve from 0.13567\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.2120 - accuracy: 0.9333 - val_loss: 0.1389 - val_accuracy: 0.9451\n",
      "Epoch 148/200\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.2135 - accuracy: 0.9304\n",
      "Epoch 148: val_loss did not improve from 0.13567\n",
      "23/23 [==============================] - 1s 37ms/step - loss: 0.2122 - accuracy: 0.9298 - val_loss: 0.1370 - val_accuracy: 0.9478\n",
      "Epoch 149/200\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.2130 - accuracy: 0.9308\n",
      "Epoch 149: val_loss did not improve from 0.13567\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.2050 - accuracy: 0.9333 - val_loss: 0.1381 - val_accuracy: 0.9451\n",
      "Epoch 150/200\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 0.2123 - accuracy: 0.9305\n",
      "Epoch 150: val_loss did not improve from 0.13567\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.2114 - accuracy: 0.9319 - val_loss: 0.1401 - val_accuracy: 0.9505\n",
      "Epoch 151/200\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.2146 - accuracy: 0.9360\n",
      "Epoch 151: val_loss did not improve from 0.13567\n",
      "23/23 [==============================] - 1s 22ms/step - loss: 0.2154 - accuracy: 0.9333 - val_loss: 0.1376 - val_accuracy: 0.9533\n",
      "Epoch 152/200\n",
      "19/23 [=======================>......] - ETA: 0s - loss: 0.2201 - accuracy: 0.9317\n",
      "Epoch 152: val_loss did not improve from 0.13567\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.2181 - accuracy: 0.9305 - val_loss: 0.1383 - val_accuracy: 0.9505\n",
      "Epoch 153/200\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.2069 - accuracy: 0.9360\n",
      "Epoch 153: val_loss did not improve from 0.13567\n",
      "23/23 [==============================] - 1s 22ms/step - loss: 0.2069 - accuracy: 0.9360 - val_loss: 0.1425 - val_accuracy: 0.9478\n",
      "Epoch 154/200\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.2178 - accuracy: 0.9325\n",
      "Epoch 154: val_loss did not improve from 0.13567\n",
      "23/23 [==============================] - 0s 22ms/step - loss: 0.2164 - accuracy: 0.9319 - val_loss: 0.1392 - val_accuracy: 0.9560\n",
      "Epoch 155/200\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.2163 - accuracy: 0.9326\n",
      "Epoch 155: val_loss did not improve from 0.13567\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.2163 - accuracy: 0.9326 - val_loss: 0.1399 - val_accuracy: 0.9533\n",
      "Epoch 156/200\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.2106 - accuracy: 0.9367\n",
      "Epoch 156: val_loss did not improve from 0.13567\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.2106 - accuracy: 0.9367 - val_loss: 0.1397 - val_accuracy: 0.9588\n",
      "Epoch 157/200\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.2099 - accuracy: 0.9347\n",
      "Epoch 157: val_loss did not improve from 0.13567\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.2099 - accuracy: 0.9347 - val_loss: 0.1378 - val_accuracy: 0.9451\n",
      "Epoch 158/200\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 0.2159 - accuracy: 0.9359\n",
      "Epoch 158: val_loss improved from 0.13567 to 0.13385, saving model to saved_models/model_(3).hdf5\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.2129 - accuracy: 0.9367 - val_loss: 0.1339 - val_accuracy: 0.9505\n",
      "Epoch 159/200\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 0.1948 - accuracy: 0.9352\n",
      "Epoch 159: val_loss did not improve from 0.13385\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.2082 - accuracy: 0.9312 - val_loss: 0.1357 - val_accuracy: 0.9478\n",
      "Epoch 160/200\n",
      "19/23 [=======================>......] - ETA: 0s - loss: 0.2343 - accuracy: 0.9276\n",
      "Epoch 160: val_loss did not improve from 0.13385\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.2195 - accuracy: 0.9319 - val_loss: 0.1385 - val_accuracy: 0.9560\n",
      "Epoch 161/200\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.2065 - accuracy: 0.9389\n",
      "Epoch 161: val_loss did not improve from 0.13385\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.2096 - accuracy: 0.9360 - val_loss: 0.1349 - val_accuracy: 0.9478\n",
      "Epoch 162/200\n",
      "19/23 [=======================>......] - ETA: 0s - loss: 0.2066 - accuracy: 0.9326\n",
      "Epoch 162: val_loss did not improve from 0.13385\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.1966 - accuracy: 0.9381 - val_loss: 0.1361 - val_accuracy: 0.9451\n",
      "Epoch 163/200\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.2160 - accuracy: 0.9297\n",
      "Epoch 163: val_loss did not improve from 0.13385\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.2173 - accuracy: 0.9292 - val_loss: 0.1361 - val_accuracy: 0.9451\n",
      "Epoch 164/200\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.2216 - accuracy: 0.9276\n",
      "Epoch 164: val_loss did not improve from 0.13385\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.2183 - accuracy: 0.9292 - val_loss: 0.1348 - val_accuracy: 0.9505\n",
      "Epoch 165/200\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 0.2108 - accuracy: 0.9383\n",
      "Epoch 165: val_loss did not improve from 0.13385\n",
      "23/23 [==============================] - 1s 22ms/step - loss: 0.2086 - accuracy: 0.9367 - val_loss: 0.1365 - val_accuracy: 0.9478\n",
      "Epoch 166/200\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.2018 - accuracy: 0.9442\n",
      "Epoch 166: val_loss did not improve from 0.13385\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 0.2125 - accuracy: 0.9395 - val_loss: 0.1356 - val_accuracy: 0.9478\n",
      "Epoch 167/200\n",
      "19/23 [=======================>......] - ETA: 0s - loss: 0.2208 - accuracy: 0.9375\n",
      "Epoch 167: val_loss improved from 0.13385 to 0.13354, saving model to saved_models/model_(3).hdf5\n",
      "23/23 [==============================] - 1s 26ms/step - loss: 0.2074 - accuracy: 0.9395 - val_loss: 0.1335 - val_accuracy: 0.9451\n",
      "Epoch 168/200\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.2099 - accuracy: 0.9367\n",
      "Epoch 168: val_loss did not improve from 0.13354\n",
      "23/23 [==============================] - 1s 28ms/step - loss: 0.2099 - accuracy: 0.9367 - val_loss: 0.1358 - val_accuracy: 0.9533\n",
      "Epoch 169/200\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.2052 - accuracy: 0.9311\n",
      "Epoch 169: val_loss did not improve from 0.13354\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.2083 - accuracy: 0.9312 - val_loss: 0.1375 - val_accuracy: 0.9478\n",
      "Epoch 170/200\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.2288 - accuracy: 0.9256\n",
      "Epoch 170: val_loss improved from 0.13354 to 0.13328, saving model to saved_models/model_(3).hdf5\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.2189 - accuracy: 0.9285 - val_loss: 0.1333 - val_accuracy: 0.9533\n",
      "Epoch 171/200\n",
      "19/23 [=======================>......] - ETA: 0s - loss: 0.2051 - accuracy: 0.9391\n",
      "Epoch 171: val_loss did not improve from 0.13328\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.2036 - accuracy: 0.9347 - val_loss: 0.1353 - val_accuracy: 0.9533\n",
      "Epoch 172/200\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.2111 - accuracy: 0.9325\n",
      "Epoch 172: val_loss did not improve from 0.13328\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.2107 - accuracy: 0.9326 - val_loss: 0.1336 - val_accuracy: 0.9478\n",
      "Epoch 173/200\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 0.2131 - accuracy: 0.9336\n",
      "Epoch 173: val_loss did not improve from 0.13328\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.2086 - accuracy: 0.9340 - val_loss: 0.1336 - val_accuracy: 0.9505\n",
      "Epoch 174/200\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.2019 - accuracy: 0.9304\n",
      "Epoch 174: val_loss improved from 0.13328 to 0.13241, saving model to saved_models/model_(3).hdf5\n",
      "23/23 [==============================] - 1s 34ms/step - loss: 0.2007 - accuracy: 0.9312 - val_loss: 0.1324 - val_accuracy: 0.9533\n",
      "Epoch 175/200\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.1924 - accuracy: 0.9389\n",
      "Epoch 175: val_loss did not improve from 0.13241\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.1897 - accuracy: 0.9402 - val_loss: 0.1335 - val_accuracy: 0.9533\n",
      "Epoch 176/200\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.2187 - accuracy: 0.9308\n",
      "Epoch 176: val_loss did not improve from 0.13241\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.2116 - accuracy: 0.9340 - val_loss: 0.1342 - val_accuracy: 0.9505\n",
      "Epoch 177/200\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.2047 - accuracy: 0.9375\n",
      "Epoch 177: val_loss did not improve from 0.13241\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.1997 - accuracy: 0.9367 - val_loss: 0.1375 - val_accuracy: 0.9560\n",
      "Epoch 178/200\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 0.2117 - accuracy: 0.9383\n",
      "Epoch 178: val_loss did not improve from 0.13241\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.2069 - accuracy: 0.9374 - val_loss: 0.1352 - val_accuracy: 0.9533\n",
      "Epoch 179/200\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.2138 - accuracy: 0.9397\n",
      "Epoch 179: val_loss did not improve from 0.13241\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.2077 - accuracy: 0.9402 - val_loss: 0.1339 - val_accuracy: 0.9560\n",
      "Epoch 180/200\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 0.1948 - accuracy: 0.9281\n",
      "Epoch 180: val_loss did not improve from 0.13241\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 0.1978 - accuracy: 0.9285 - val_loss: 0.1382 - val_accuracy: 0.9478\n",
      "Epoch 181/200\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.2188 - accuracy: 0.9311\n",
      "Epoch 181: val_loss did not improve from 0.13241\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.2145 - accuracy: 0.9326 - val_loss: 0.1389 - val_accuracy: 0.9451\n",
      "Epoch 182/200\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 0.1896 - accuracy: 0.9383\n",
      "Epoch 182: val_loss did not improve from 0.13241\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.1957 - accuracy: 0.9374 - val_loss: 0.1433 - val_accuracy: 0.9560\n",
      "Epoch 183/200\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.2008 - accuracy: 0.9315\n",
      "Epoch 183: val_loss did not improve from 0.13241\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 0.1984 - accuracy: 0.9340 - val_loss: 0.1386 - val_accuracy: 0.9533\n",
      "Epoch 184/200\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.1961 - accuracy: 0.9347\n",
      "Epoch 184: val_loss did not improve from 0.13241\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.1924 - accuracy: 0.9360 - val_loss: 0.1409 - val_accuracy: 0.9560\n",
      "Epoch 185/200\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 0.1958 - accuracy: 0.9391\n",
      "Epoch 185: val_loss did not improve from 0.13241\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.1988 - accuracy: 0.9381 - val_loss: 0.1342 - val_accuracy: 0.9505\n",
      "Epoch 186/200\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.1976 - accuracy: 0.9354\n",
      "Epoch 186: val_loss did not improve from 0.13241\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.1976 - accuracy: 0.9354 - val_loss: 0.1349 - val_accuracy: 0.9478\n",
      "Epoch 187/200\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.2021 - accuracy: 0.9368\n",
      "Epoch 187: val_loss did not improve from 0.13241\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.2008 - accuracy: 0.9374 - val_loss: 0.1359 - val_accuracy: 0.9533\n",
      "Epoch 188/200\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.2151 - accuracy: 0.9325\n",
      "Epoch 188: val_loss did not improve from 0.13241\n",
      "23/23 [==============================] - 1s 41ms/step - loss: 0.2115 - accuracy: 0.9340 - val_loss: 0.1362 - val_accuracy: 0.9451\n",
      "Epoch 189/200\n",
      "19/23 [=======================>......] - ETA: 0s - loss: 0.2194 - accuracy: 0.9342\n",
      "Epoch 189: val_loss improved from 0.13241 to 0.13223, saving model to saved_models/model_(3).hdf5\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 0.2085 - accuracy: 0.9367 - val_loss: 0.1322 - val_accuracy: 0.9533\n",
      "Epoch 190/200\n",
      "19/23 [=======================>......] - ETA: 0s - loss: 0.1962 - accuracy: 0.9416\n",
      "Epoch 190: val_loss did not improve from 0.13223\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.2104 - accuracy: 0.9402 - val_loss: 0.1329 - val_accuracy: 0.9533\n",
      "Epoch 191/200\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 0.2071 - accuracy: 0.9367\n",
      "Epoch 191: val_loss improved from 0.13223 to 0.13090, saving model to saved_models/model_(3).hdf5\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.1984 - accuracy: 0.9395 - val_loss: 0.1309 - val_accuracy: 0.9505\n",
      "Epoch 192/200\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.1991 - accuracy: 0.9375\n",
      "Epoch 192: val_loss did not improve from 0.13090\n",
      "23/23 [==============================] - 1s 33ms/step - loss: 0.1977 - accuracy: 0.9374 - val_loss: 0.1366 - val_accuracy: 0.9533\n",
      "Epoch 193/200\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.1913 - accuracy: 0.9425\n",
      "Epoch 193: val_loss did not improve from 0.13090\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.1906 - accuracy: 0.9422 - val_loss: 0.1349 - val_accuracy: 0.9533\n",
      "Epoch 194/200\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.2001 - accuracy: 0.9330\n",
      "Epoch 194: val_loss did not improve from 0.13090\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.1993 - accuracy: 0.9354 - val_loss: 0.1321 - val_accuracy: 0.9505\n",
      "Epoch 195/200\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.2189 - accuracy: 0.9293\n",
      "Epoch 195: val_loss did not improve from 0.13090\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.2084 - accuracy: 0.9340 - val_loss: 0.1332 - val_accuracy: 0.9533\n",
      "Epoch 196/200\n",
      "19/23 [=======================>......] - ETA: 0s - loss: 0.2013 - accuracy: 0.9375\n",
      "Epoch 196: val_loss did not improve from 0.13090\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.2116 - accuracy: 0.9312 - val_loss: 0.1396 - val_accuracy: 0.9588\n",
      "Epoch 197/200\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.2044 - accuracy: 0.9382\n",
      "Epoch 197: val_loss did not improve from 0.13090\n",
      "23/23 [==============================] - 1s 28ms/step - loss: 0.2059 - accuracy: 0.9367 - val_loss: 0.1322 - val_accuracy: 0.9505\n",
      "Epoch 198/200\n",
      "19/23 [=======================>......] - ETA: 0s - loss: 0.1916 - accuracy: 0.9359\n",
      "Epoch 198: val_loss did not improve from 0.13090\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.1922 - accuracy: 0.9340 - val_loss: 0.1355 - val_accuracy: 0.9533\n",
      "Epoch 199/200\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.1848 - accuracy: 0.9345\n",
      "Epoch 199: val_loss did not improve from 0.13090\n",
      "23/23 [==============================] - 1s 37ms/step - loss: 0.1890 - accuracy: 0.9347 - val_loss: 0.1449 - val_accuracy: 0.9588\n",
      "Epoch 200/200\n",
      "19/23 [=======================>......] - ETA: 0s - loss: 0.1873 - accuracy: 0.9375\n",
      "Epoch 200: val_loss did not improve from 0.13090\n",
      "23/23 [==============================] - 1s 32ms/step - loss: 0.2048 - accuracy: 0.9340 - val_loss: 0.1410 - val_accuracy: 0.9560\n",
      "Training completed in time:  0:02:00.967345\n"
     ]
    }
   ],
   "source": [
    "## Trianing my model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from datetime import datetime \n",
    "\n",
    "num_epochs = 200\n",
    "num_batch_size = 64\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/model_(3).hdf5', verbose=1, save_best_only=True)\n",
    "start = datetime.now()\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(X_test, y_test), callbacks=[checkpointer], verbose=1)\n",
    "\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "virgin-butter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9560439586639404\n"
     ]
    }
   ],
   "source": [
    "test_accuracy=model.evaluate(X_test,y_test,verbose=0)\n",
    "print(test_accuracy[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a5beb1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9505494236946106\n"
     ]
    }
   ],
   "source": [
    "model2 = tf.keras.models.load_model('/home/ammar/Desktop/VectraCom/mustanad_jawab/saved_models/model_(3).hdf5')\n",
    "test_accuracy=model2.evaluate(X_test,y_test,verbose=0)\n",
    "print(test_accuracy[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chubby-newsletter",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=\"/home/ammar/Desktop/VectraCom/mustanad_jawab/assets/test_files/923185705003_VXT_Khwab_IVR_Q_20220606002812.wav\"\n",
    "prediction_feature=features_extractor(filename)\n",
    "prediction_feature=prediction_feature.reshape(1,-1)\n",
    "class_prob = model.predict(prediction_feature)\n",
    "predicted_class = tf.argmax(class_prob, axis=1)\n",
    "predicted_label = predicted_class.numpy()[0]\n",
    "print(predicted_label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
